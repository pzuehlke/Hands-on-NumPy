{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra with NumPy\n",
    "\n",
    "In the previous notebooks we explored NumPy arrays and their basic operations.\n",
    "Here we'll focus on the basic NumPy commands for doing Linear Algebra, which is\n",
    "perhaps even more important than Calculus for many engineering applications,\n",
    "such as structural analysis, signal processing, optimization and circuit\n",
    "analysis, among others. It is also essential for machine learning and computer graphics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $ \\S 1 $ Basic operations on vectors\n",
    "\n",
    "### $ 1.1 $ Vector addition and scalar multiplication\n",
    "\n",
    "We saw in the previous notebook that a vector such as $ (1, 2, 3) $\n",
    "can be represented in NumPy as a $ 1D $ array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([1, 2, 3])\n",
    "w = np.array([4, 5, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use NumPy to perform all of the familiar operations on vectors.\n",
    "\n",
    "Given vectors $ \\mathbf v = (v_1, v_2, \\cdots, v_n) $ and $ \\mathbf w = (w_1,\n",
    "w_2, \\cdots, w_n) $ with the same number of coordinates, their __sum__ and\n",
    "__difference__ are computed element-wise:\n",
    "$$\n",
    "\\begin{alignat*}{2}\n",
    "\\mathbf{v} + \\mathbf{w} &= (v_1 + w_1, v_2 + w_2, \\ldots, v_n + w_n) \\\\\n",
    "\\mathbf{v} - \\mathbf{w} &= (v_1 - w_1, v_2 - w_2, \\ldots, v_n - w_n)\n",
    "\\end{alignat*}\n",
    "$$\n",
    "NumPy uses the same notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = v + w\n",
    "print(s, type(s))\n",
    "\n",
    "d = v - w\n",
    "print(d, type(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Scalar multiplication__ of a vector by a factor $ c \\in \\mathbb{R} $ is also defined\n",
    "element-wise:\n",
    "$$\n",
    "c\\, \\mathbf v = (c\\,v_1, c\\,v_2, \\cdots, c\\,v_n)\\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2 * v)\n",
    "print(-3.14 * v)\n",
    "print(0 * v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, we may also write $ -\\mathbf v $ instead of $ (-1)\\mathbf v $. Try it in the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we operate on an array whose datatype is `int` and any floating-number is\n",
    "involved in the operation, then the result will be of datatype `float`.  A similar\n",
    "observation applies to any other type coercion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `v.dtype` yields the datatype of the elements of v.\n",
    "# We will study `dtype` in more detail later.\n",
    "v = np.array([1, 2, 3])\n",
    "print(v, v.dtype)\n",
    "\n",
    "u = 1.0 * v\n",
    "print(u, u.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise:__ Can you explain the output of the following cell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-1, 0, 1, 3])\n",
    "b = np.array([True, False, True, False])\n",
    "\n",
    "x_plus_b = x + b\n",
    "print(x_plus_b, x_plus_b.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ 1.2 $ Dot products\n",
    "\n",
    "The __dot product__ $ \\mathbf v \\cdot \\mathbf w $ of two vectors $ \\mathbf v =\n",
    "(w_1, w_2, \\cdots, w_n) $ and $ \\mathbf w  = (w_1, w_2, \\cdots, w_n) $ of the\n",
    "same shape is the sum of the products of their corresponding coordinates:\n",
    "$$\n",
    "\\boxed{\\ \\mathbf v \\cdot \\mathbf w = \\sum_{i=1}^n v_i\\,w_i =  v_1w_1 + v_2w_2 + \\cdots + v_nw_n\\ } \n",
    "$$\n",
    "The `dot` function computes dot products:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([1, 0, -1])\n",
    "\n",
    "dot_product = np.dot(a, b)\n",
    "print(dot_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalently, we can also use the `@` operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alternative_dot_product = a @ b\n",
    "print(alternative_dot_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise:__ Compute the dot product of $ \\mathbf{v} = (2, 3, -1) $ and\n",
    "$ \\mathbf{w} = (4, 0, 5) $ using `dot` and `@`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to verify directly from the definition that the dot product is both:\n",
    "* symmetric, i.e.,\n",
    "    $$ \\mathbf v \\cdot \\mathbf w = \\mathbf w \\cdot \\mathbf v $$\n",
    "* bilinear, meaning that \n",
    "\\begin{alignat*}{9}\n",
    "    (a\\, \\mathbf u + b\\,\\mathbf v) \\cdot \\mathbf w\n",
    "    &= a\\, (\\mathbf u \\cdot \\mathbf w) + b\\, (\\mathbf v \\cdot \\mathbf w) \\\\\n",
    "    \\mathbf u \\cdot (a\\,\\mathbf v + b\\,\\mathbf w) \n",
    "    &= a\\, (\\mathbf u \\cdot \\mathbf v) + b\\, (\\mathbf u \\cdot \\mathbf w)\\,.\n",
    "\\end{alignat*}\n",
    "\n",
    "Here $ \\mathbf u,\\,\\mathbf v,\\, \\mathbf w \\in \\mathbb R^n $ and $ a,\\,b \\in \\mathbb R\\, $ are arbitrary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ 1.3 $ Vector norm\n",
    "\n",
    "The __norm__ or __length__ of a vector\n",
    "$ \\mathbf v = (v_1, v_2, \\cdots, v_n) \\in \\mathbb R^n $ is defined by\n",
    "$$\n",
    "\\boxed{\\ \\Vert \\mathbf v \\Vert = \\sqrt{\\mathbf v \\cdot \\mathbf v} = \\sqrt{v_1^2 + v_2^2 + \\cdots + v_n^2}\\ } $$\n",
    "In dimension $ 2 $, this definition of \"length\" matches our intuitive notion and\n",
    "can be justified by a simple application of Pythagoras' theorem, as illustrated\n",
    "in the figure below. \n",
    "\n",
    "<img src=\"notebook_3_vector.png\" alt=\"Vector\" width=\"500px\">\n",
    "\n",
    "In higher dimensions we could similarly derive the formula for the length using\n",
    "Pythagoras' theorem and induction. For example, the norm (length) of the vector\n",
    "$ \\mathbf w = (1, -2, 3) \\in \\mathbb R^3 $ is\n",
    "$ \\Vert \\mathbf{w} \\Vert = \\sqrt{1^2 + (-2)^2 + 3^2} = \\sqrt{14} $.\n",
    "\n",
    "\n",
    "In NumPy, the norm of a vector can be easily computed with a call to the \n",
    "function `norm` from the `linalg` submodule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([3, 4])\n",
    "\n",
    "print(np.linalg.norm(v))\n",
    "\n",
    "# Alternatively, we could take the square root of the dot product:\n",
    "print(np.sqrt(v @ v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise:__ Verify with the help of NumPy that the length of\n",
    "$ \\mathbf{u} = \\big(\\frac{1}{2}, \\frac{1}{2}, \\frac{1}{2}, \\frac{1}{2} \\big) \\in \\mathbb R^4 $\n",
    "is $ 1 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö° We can also use `norm` to compute different norms, for instance:\n",
    "$$\n",
    "\\begin{alignat*}{2}\n",
    "    \\|\\mathbf{v}\\|_1 &= \\sum_{i=1}^n |v_i| &\\quad& \\text{($ L_1 $ norm for $\\mathbf{v} \\in \\mathbb{R}^n$)} \\\\\n",
    "    \\|\\mathbf{v}\\|_{\\infty} &= \\max_{1 \\leq i \\leq n} |v_i| && \\text{($ L_\\infty$ norm for $\\mathbf{v} \\in \\mathbb{R}^n$)}\n",
    "\\end{alignat*}\n",
    "$$\n",
    "In this notation, the usual (Euclidean) norm is also called the $ L_2 $ norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise:__ Let\n",
    "$ \\mathbf{u} = \\big(\\frac{1}{2}, \\frac{1}{2}, \\frac{1}{2}, \\frac{1}{2} \\big) \\in \\mathbb R^4 $.\n",
    "Compute its $ L_1 $ and $ L_\\infty $ norms by providing the additional arguments\n",
    "`ord=1` and `ord=np.inf` to the `norm` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_u_1 = # ...    # L_1 norm (Manhattan distance)\n",
    "norm_u_inf = # ...    # L_infinity norm (maximum absolute value)\n",
    "\n",
    "print(f\"L_1 norm of u = {norm_u_1}\")\n",
    "print(f\"L_infinity norm of u = {norm_u_inf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ 1.4 $ The geometry of dot products\n",
    "\n",
    "Recall that two vectors are __orthogonal__ (or __perpendicular__) if and only if\n",
    "their dot product vanishes. \n",
    "\n",
    "__Exercise:__ Determine whether the two vectors below are orthogonal by\n",
    "computing their dot product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([-3, 4, 7, 3, -6])\n",
    "b = np.array([2, 5, -2, 4, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More generally, recall from Linear Algebra the following relationship between the dot product and\n",
    "the smallest angle $ \\theta \\in [0, \\pi] $ between two nonzero vectors:\n",
    "$$\n",
    "\\boxed{\\ \\cos \\theta = \\frac{\\mathbf v \\cdot \\mathbf w}{\\Vert \\mathbf v \\Vert \\,\\Vert \\mathbf w \\Vert}\\ }\n",
    "$$\n",
    "                                                                                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise:__ Compute the angle between the vectors $ \\mathbf v = (2, 0) $ and\n",
    "$ \\mathbf w = (3, 3) $ in degrees. Check your answer against the figure below.\n",
    "_Hint:_ Use `np.arccos` to compute the arccosine and `np.degrees` to transform\n",
    "the result to degrees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"notebook_3_vectors_and_angle.png\" alt=\"Angle\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise:__ Consider the vectors $ \\mathbf a $ and $ \\mathbf b $ in the \n",
    "figure below. Project $ \\mathbf b $ orthogonally onto the line spanned\n",
    "by $ \\mathbf a $. That is, compute the projection\n",
    "$$ \\boxed{\\ \\mathbf p = \\frac{\\mathbf b \\cdot \\mathbf a}{\\Vert \\mathbf{a} \\Vert^2}\\, \\mathbf a\n",
    "= \\frac{\\mathbf b \\cdot \\mathbf a}{\\mathbf a \\cdot \\mathbf a}\\, \\mathbf a\\ } $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"notebook_3_projection.png\" alt=\"Projection\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = ...\n",
    "# b = ...\n",
    "# p = ...\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A __unit vector__ is a vector of length $ 1 $. To get a unit vector $ \\mathbf u $ having the same\n",
    "direction as a given nonzero vector $ \\mathbf v $, we can simply divide the latter by its norm:\n",
    "$$\n",
    "    \\mathbf u = \\frac{\\mathbf v}{\\Vert \\mathbf v \\Vert}\\,.\n",
    "$$\n",
    "Indeed, using the properties of the dot product and the definition of the norm, we can check directly that\n",
    "$$\n",
    "    \\mathbf u \\cdot \\mathbf u = \\bigg(\\frac{\\mathbf v}{\\Vert \\mathbf v \\Vert}\\bigg) \\cdot \\bigg(\\frac{\\mathbf v}{\\Vert \\mathbf v \\Vert}\\bigg)\n",
    "    = \\frac{{\\mathbf v \\cdot \\mathbf v}}{\\Vert \\mathbf v \\Vert^2} = 1\\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise:__ How many _unit_ vectors in $ \\mathbb{R}^3 $ are parallel to $ \\mathbf v = (3, -4, 12) $ (i.e., lie on the same line through the origin as $ \\mathbf v $)? Compute all of them using NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([3, -4, 12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise:__ The __canonical basis__ in $ \\mathbb R^3 $ consists of the three vectors\n",
    "$$ \\mathbf e_1 = (1, 0, 0)\\,, \\quad \\mathbf e_2 = (0, 1, 0)\\,, \\quad \\text{and} \\quad \\mathbf e_3 = (0, 0, 1) \\,,$$\n",
    "which have norm $ 1 $ and point in the same direction as the positive $ x $-, $ y $- and $ z$-axis, respectively.\n",
    "Compute all possible dot products $ \\mathbf e_i \\cdot \\mathbf e_j $.\n",
    "Store the dot products in a $ 3 \\times 3 $ matrix whose $ (i, j) $-th entry\n",
    "equals $ \\mathbf{e}_i \\cdot \\mathbf{e}_j $.\n",
    " _Hint:_ Store the vectors in a list and use two for loops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ 1.5 $ The cross product\n",
    "\n",
    "The __cross product__ $ \\mathbf v \\times \\mathbf w \\in \\mathbb R^3 $ of two vectors _in\n",
    "three-dimensional space_ results in a vector that:\n",
    "1. is orthogonal to both $ \\mathbf v $ and $ \\mathbf w $;\n",
    "2. has length given by\n",
    "$$\n",
    "\\boxed{\\ \\Vert{\\mathbf v \\times \\mathbf w}\\Vert = \\Vert{\\mathbf v}\\Vert\\,\\Vert{\\mathbf w}\\Vert\\,\\sin \\theta\\ }\n",
    "$$\n",
    "where again $ \\theta \\in [0, \\pi] $ denotes the smallest angle between\n",
    "$ \\mathbf v $ and $ \\mathbf w $. Note that the expression on the right\n",
    "coincides with the area of the parallelogram spanned by $ \\mathbf{v} $ and $\n",
    "\\mathbf{w} $.\n",
    "\n",
    "The cross product is uniquely determined by these two properties together with\n",
    "the fact that:\n",
    "\n",
    "3. the basis $ \\big(\\mathbf v,\\, \\mathbf w,\\, \\mathbf v \\times \\mathbf w \\big) $ is _positively oriented_ (i.e., this\n",
    "trio of vectors, in this order, satisfies the \"right-hand rule\").\n",
    "\n",
    "\n",
    "<img src=\"notebook_3_cross_product.png\" alt=\"Projection\" width=\"500px\">\n",
    "\n",
    "Like the dot product, the cross product $ \\times $ is also bilinear, but it is\n",
    "antisymmetric instead of symmetric:\n",
    "$$ \\mathbf w \\times \\mathbf v = -\\mathbf v \\times \\mathbf w \\quad (\\mathbf v,\\, \\mathbf w \\in \\mathbb R^3)\\,.\n",
    "$$\n",
    "Cross products can be computed in NumPy with the function `cross`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise:__ Let $ \\mathbf{a} = (2, 1, 0) $ and $ \\mathbf{b} = (1, 2, 0) $. Use\n",
    "`cross` to verify that:\n",
    "\n",
    "(a) $ \\mathbf{a} \\times \\mathbf{b} = (0, 0, 3) $.\n",
    "\n",
    "(b) $ \\mathbf{b} \\times \\mathbf{a} = - \\mathbf{a} \\times \\mathbf{b} $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $ \\S 2 $ Basic operations involving matrices\n",
    "\n",
    "### $ 2.1 $ Addition, subtraction and scalar multiplication\n",
    "\n",
    "Recall that matrices are represented in NumPy as $ 2D $ arrays. Just as for\n",
    "vectors, we can __add__ and __subtract__ two matrices, or more generally any two\n",
    "arrays having the same shape, using `+` and `-` respectively.\n",
    "Matrix addition and subtraction are performed element-wise: if $ A = (a_{ij}) $\n",
    "and $ B = (b_{ij}) $, then\n",
    "$$\n",
    "\\begin{align*}\n",
    "A + B &= (a_{ij} + b_{ij}) \\\\\n",
    "A - B &= (a_{ij} - b_{ij})\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "__Exercise:__ Compute the sum and difference of the matrices $ A $ and $ B $\n",
    "given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2, 3],\n",
    "              [1, 2, 3]])\n",
    "\n",
    "B = np.array([[4, 4, 4],\n",
    "              [5, 5, 5]])\n",
    "\n",
    "# S = ... (sum)\n",
    "# D = ... (difference)\n",
    "\n",
    "print(\"Matrix A:\\n\", A, '\\n')\n",
    "print(\"Matrix B:\\n\", B, '\\n')\n",
    "print(\"Sum:\\n\", S, '\\n')\n",
    "print(\"Difference:\\n\", D, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, to __scale__ every element of a matrix (or, more generally, $ n\n",
    "$-dimensional array) $ A $ by a scalar $ c $, we may use either `c * A` or `A * c`.\n",
    "\n",
    "__Exercise:__  Compute $ 2M $ in by multiplying $ M $ by $ 2 $ both on the right\n",
    "and on the left, where:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([\n",
    "    [4, 7, 2],\n",
    "    [9, 1, 5]\n",
    "])\n",
    "c = 2\n",
    "\n",
    "# print(\"cM:\\n\", ... )\n",
    "# print(\"Mc:\\n\", ... )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ 2.2 $ Matrix multiplication\n",
    "\n",
    "\n",
    "__Matrix multiplication__ is the most fundamental operation in linear algebra.\n",
    "Given matrices $ A $ of shape $ (m, n) $ and $ B $ of shape $ (n, p) $, their\n",
    "product $ C = A B $ is a matrix of shape $ (m, p) $. The $ (i, j) $-th entry of\n",
    "$ C $, denoted $ C_{ij} $, is the dot product of the $ i $-th row of $ A $ and the\n",
    "$ j $-th column of $ B $:\n",
    "$$\n",
    "\\boxed{\\ C_{ij} = (\\textbf{$ \\mathbf{i} $-th row of $ \\mathbf{A} $}) \\cdot (\\textbf{$ \\mathbf{j} $-th column of $ \\mathbf{B} $})\n",
    "= \\sum_{k=1}^{n} A_{ik} B_{kj}\\ }\n",
    "$$\n",
    "In particular, for the product of two matrices to make sense, the number of\n",
    "columns in the first matrix must match the number of rows in the second matrix.\n",
    "Matrix multiplication should not be confused with element-wise multiplication,\n",
    "which is less frequently needed in Linear Algebra.\n",
    "\n",
    "In NumPy, matrix multiplication can be performed using the `matmul` or\n",
    "`dot` functions, or the `@` operator. \n",
    "\n",
    "__Exercise:__ Compute the product $ AB $ of the matrices $ A $ and $ B $\n",
    "below in these three ways, and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a 2 x 3 matrix A:\n",
    "A = np.array([[1, 2, 3],\n",
    "              [4, 5, 6]])\n",
    "\n",
    "# Creating a 3 x 4 matrix B:\n",
    "B = np.array([[7, 8, 9, 10],\n",
    "              [11, 12, 13, 14],\n",
    "              [15, 16, 17, 18]])\n",
    "\n",
    "# P_1 =      (using np.matmul())\n",
    "# P_2 =      (using np.dot())\n",
    "# P_3 =      (using the @ operator)\n",
    "\n",
    "print(P_1, '\\n')\n",
    "print(P_2, '\\n')\n",
    "print(P_3, '\\n')\n",
    "print(P_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìù For matrix multiplication, `dot`, `matmul` and `@` are completely equivalent\n",
    "in their output and performance. The choice between them is a matter of\n",
    "preference and code readability.\n",
    "\n",
    "When multiplying a $ 2D $ array (matrix) by a $ 1D $ array (vector), the vector\n",
    "is temporarily viewed as a column matrix and the operation is treated as a\n",
    "matrix multiplication. Thus, matrix-vector multiplication can also be handled\n",
    "by `@`, `dot` or `matmul`.\n",
    "\n",
    "__Exercise:__ Compute the product $ A \\mathbf{v} $ for $ A $ and $ \\mathbf{v} $\n",
    "as given below in these three ways. Determine the shape of the result;\n",
    "is it a $ 1D $ array or a $ 2D $ array with only one column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2, 3],\n",
    "              [4, 5, 6]])\n",
    "v = np.array([-1, 0, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è It is a common mistake for programmers to use the `*` operator when\n",
    "matrix multiplication is intended. However, `A * B` gives the\n",
    "_element-wise product of $ A $ and $ B $._\n",
    "\n",
    "__Exercise:__ Compute `C @ C`, `C * C`, `C**2` and `C**(-1)` for the matrix $ C $ below. Can you explain these results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.array([[1.0, 1.0, 1.0],\n",
    "              [2.0, 2.0, 2.0],\n",
    "              [-3., -3., -3.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è Matrix multiplication is not commutative: $ A B \\neq B A $ in general.\n",
    "\n",
    "__Exercise:__ Let \n",
    "$$\n",
    "    P = \\begin{bmatrix} 2 & 0 \\\\ -1 & 3 \\end{bmatrix} \\quad \\text{and} \\quad \n",
    "    Q = \\begin{bmatrix} 1 & 4 \\\\ 2 & -3 \\end{bmatrix}\n",
    "$$\n",
    "Check whether $ P Q = Q P $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise:__ For real numbers $ a,\\, b $, if $ a $ and $ b $ are both nonzero,\n",
    "then so is their product $ ab $. Is this also true of matrices? _Hint:_ Try to\n",
    "find a nonzero $ 2 \\times 2 $ matrix $ A $ such that $ A^2 $ is the null $ 2\n",
    "\\times 2 $ matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the $ n $-th power of a matrix $ A $, we can use `np.linalg.matrix_power(A, n)`.\n",
    "As an application, consider the directed graph below:\n",
    "\n",
    "<img src=\"notebook_3_graph.png\" alt=\"Directed graph\" width=\"300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __adjacency matrix__  $ A $ for this graph is a $ 4 \\times 4 $ matrix \n",
    "whose $ (i, j) $-th entry equals $ 1 $ if there's an edge from vertex $ i $ to\n",
    "vertex $ j $ and $ 0 $ otherwise. (We start counting $ i $ and $ j $ from $ 0 $\n",
    "to be consistent with our code.) Thus, in our case:\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "0 & 1 & 1 & 0 \\\\\n",
    "0 & 0 & 1 & 0 \\\\\n",
    "1 & 0 & 0 & 1 \\\\\n",
    "0 & 1 & 0 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The powers of an adjacency matrix have a beautiful interpretation in graph theory:\n",
    "* $ A^1 = A $, the adjacency matrix itself, shows direct connections between nodes;\n",
    "* $ A^2 $ shows the number of paths of length $ 2 $ between nodes;\n",
    "* $ A^3 $ shows the number of paths of length $ 3 $ between nodes; and so on...\n",
    "* In general, $ A^n_{ij} $ represents the number of distinct paths of length $ n $\n",
    "  from vertex $ i $ to vertex $ j $ in the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of our graph,\n",
    "$$\n",
    "A^2 = \\begin{bmatrix}\n",
    "0 & 0 & 1 & 1 \\\\\n",
    "1 & 0 & 0 & 1 \\\\\n",
    "0 & 2 & 1 & 0 \\\\\n",
    "0 & 0 & 1 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "For example, the fact that $ A^2_{2,1} = 2 $ indicates that there are exactly\n",
    "two distinct paths of length $ 2 $ from vertex $ 2 $ to vertex $ 1 $. Indeed, we\n",
    "can check directly by looking at the graph that these paths are:\n",
    "$$\n",
    "2 \\rightarrow 0 \\rightarrow 1 \\qquad \\text{and} \\qquad 2 \\rightarrow 3 \\rightarrow 1\\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise:__ Using `np.linalg.matrix_power(A, n)`:\n",
    "\n",
    "(a) Determine the number of paths of length $ 20 $ starting at vertex $ 3 $ and\n",
    "ending at vertex $ 0 $ in the graph depicted above.\n",
    "\n",
    "(b) Determine the number of paths of length $ \\le 20 $ starting at vertex $ 1 $\n",
    "    and returning to that same vertex. _Hint:_ Use a for loop to add the relevant\n",
    "    entries in $ I + A + A^2 + \\cdots + A^{20} $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([\n",
    "    [0, 1, 1, 0],\n",
    "    [0, 0, 1, 0],\n",
    "    [1, 0, 0, 1],\n",
    "    [0, 1, 0, 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ 2.3 $ Identity and diagonal matrices\n",
    "\n",
    "To instantiate a copy of the identity matrix of shape $ n \\times n $,\n",
    "we can use the function `identity` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "I = np.identity(n)  # Create an n x n identity matrix\n",
    "print(I)\n",
    "print(I.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more flexible version of `identity` allowing the creation of non-square\n",
    "matrices is `eye` (the name comes from the letter 'I'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = np.eye(3, 4)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third (optional) parameter of `eye` specifies an offset to the diagonal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = np.eye(4, 4, 0)   # An offset of 0 corresponds to the main diagonal\n",
    "U = np.eye(4, 4, 1)   # An offset of 1 corresponds to the diagonal immediately above the main one\n",
    "L = np.eye(4, 4, -2)  # A negative offset to refers to a lower diagonal\n",
    "\n",
    "print(I, '\\n')\n",
    "print(U, '\\n')\n",
    "print(L, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise:__ Compute the linear combination $ M^2 - 3 M + 2I $, for $ M $ the matrix below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([[ 0, -2],\n",
    "              [ 1,  3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `diag` is dual-purpose: it both creates diagonal matrices and\n",
    "extracts diagonals from existing matrices, depending on its input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.diag creates a diagonal matrix when given a 1D array:\n",
    "diagonal_values = [1, 2, 3, 4]\n",
    "diag_matrix = np.diag(diagonal_values)\n",
    "print(diag_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.diag extracts the diagonal when given a 2D array:\n",
    "existing_matrix = np.array([[1, 2, 3], \n",
    "                            [4, 5, 6], \n",
    "                            [7, 8, 9]])\n",
    "diagonal = np.diag(existing_matrix)\n",
    "print(diagonal, diagonal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise:__ Extract the diagonal elements of the matrix $ C $ below into a vector and\n",
    "then compute its length and the angle it makes with the vector $ (7, -2, 1) $:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.array([[0, -4, 2],\n",
    "              [3, 1, -5],\n",
    "              [-3, 0, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ 2.5 $ Transposition\n",
    "\n",
    "The transpose of a matrix $ A $ is a new matrix $ A^T $ whose rows are the\n",
    "columns of $ A $ and vice versa. Formally, if $ A $ is an $ m \\times n $ matrix,\n",
    "then $ A^T $ is an $ n \\times m $ matrix with elements $ (A^T)_{ij} = A_{ji} $.\n",
    "In NumPy, the transpose of $ A $ is denoted by `A.T`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]] \n",
      "\n",
      "A^T:\n",
      "[[1 4 7]\n",
      " [2 5 8]\n",
      " [3 6 9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]])\n",
    "\n",
    "print(\"A:\")\n",
    "print(A, \"\\n\")\n",
    "print(\"A^T:\")\n",
    "print(A.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise:__ A square $ n \\times n $ matrix $ A $ is\n",
    "__orthogonal__ if and only if its $ n $ column vectors\n",
    "$ \\mathbf v_1, \\cdots, \\mathbf v_n $ form an _orthonormal basis_ of $ \\mathbb R^n $ that is,\n",
    "$$\n",
    "\\mathbf v_i \\cdot \\mathbf v_j = \n",
    "\\begin{cases}\n",
    "1 & \\text{if $ i = j $} \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "\\qquad \\text{for each $ i,\\,j = 1, \\cdots, n\\,. $}\n",
    "$$\n",
    "\n",
    "(a) Write a procedure `is_orthogonal` that determines whether a\n",
    "given $ n \\times n $ square matrix $ A $ is orthogonal. \n",
    "_Hint:_ Use the slice `A[:, i]` to extract the $ i $-th column vector of $ A $\n",
    "and compute all possible dot products.\n",
    "\n",
    "(b) Can you see any potential problems with your approach when $ A $\n",
    "consists of floating-point numbers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise:__ An equivalent condition for the orthogonality of $ A $ is that it satisfy\n",
    "$$\n",
    "A^TA = I_n = AA^T\\,,\n",
    "$$\n",
    "where $ A^T $ is the transpose of $ A $ and $ I_n $ is the $ n \\times n $ identity matrix.\n",
    "(Actually, any one of these equations by itself already suffices for orthogonality.)\n",
    " \n",
    "Write another version of `is_orthogonal` that makes use of this criterion and of\n",
    "the transpose `A.T`.  When comparing to the identity, you may want to use\n",
    "`np.round(B, 10)` to round all entries of $ B $ to ten decimal digits to avoid\n",
    "false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ 2.6 $ The trace, determinant and inverse of a square matrix\n",
    "\n",
    "Recall that the __trace__ of a square matrix is by definition the sum of all of\n",
    "its diagonal entries. To compute the __trace__, __determinant__ and the\n",
    "__inverse__ of a _square_ matrix, we can use the `np.trace`, `np.linalg.det` and\n",
    "the `np.linalg.inv` functions, respectively. \n",
    "\n",
    "__Exercise:__ Compute the trace, determinant and inverse $ X^{-1} $ of $ X $.\n",
    "Verify whether $ X^{-1} X = I_2 = XX^{-1} $ and explain the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[3, 1, 2],\n",
    "              [1, 5, 1],\n",
    "              [2, 1, 4]])\n",
    "\n",
    "# trace = ...\n",
    "# determinant = ...\n",
    "# inverse = ...\n",
    "print(f\"Trace of X: {trace:.4f}\")\n",
    "print(f\"Determinant of X: {determinant:.2f}\")\n",
    "print(f\"Inverse of X\\n: {inverse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise:__ Find the area of the parallelogram spanned by the vectors \n",
    "$ (3, 5) $ and $ (2, 4) $ in $ \\mathbb{R}^2 $.  Recall that this area can be\n",
    "computed as the absolute value of the determinant of the matrix formed by these\n",
    "vectors. _Hint:_ The absolute value function in NumPy is denoted by `np.abs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise:__ Given two square matrices $ C $ and $ D $ of the same size, recall\n",
    "that the determinant of their product is the product of their determinants:\n",
    "$$\n",
    "\\boxed{\\ \\det(CD) = \\det(C) \\cdot \\det(D)\\ }\n",
    "$$\n",
    "Verify this identity in the particular example where\n",
    "$$\n",
    "C = \\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4 \\\\\n",
    "\\end{bmatrix} \\quad \\text{and} \\quad\n",
    "D = \\begin{bmatrix}\n",
    "2 & 3 \\\\\n",
    "1 & 4 \\\\\n",
    "\\end{bmatrix}\\,.\n",
    "$$\n",
    "Does $ CD = DC $?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise:__ Solve the linear system of equations given by\n",
    "$ A\\mathbf{x} = \\mathbf{b} $, where\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "1 & 2 & 3 \\\\\n",
    "0 & 1 & 4 \\\\\n",
    "5 & 6 & 0 \\\\\n",
    "\\end{bmatrix} \\quad \\text{and} \\quad \\mathbf b = \\begin{bmatrix}\n",
    "3 \\\\\n",
    "7 \\\\\n",
    "8 \\\\\n",
    "\\end{bmatrix}\\,.\n",
    "$$\n",
    "Verify your answer by multiplying $ A $ by $ \\mathbf x $.\n",
    "_Hint:_ Use the inverse of $ A $ to find $ \\mathbf{x} = A^{-1}\\mathbf{b} $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö° __Exercise:__ For a list of values $ x_0, x_1, \\ldots, x_n $, the corresponding __Vandermonde\n",
    "matrix__ is defined as:\n",
    "$$\n",
    "V = \\begin{bmatrix} \n",
    "1 & x_0 & x_0^2 & \\cdots & x_0^{n} \\\\ \n",
    "1 & x_1 & x_1^2 & \\cdots & x_1^{n} \\\\ \n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ \n",
    "1 & x_n & x_n^2 & \\cdots & x_n^{n}\n",
    "\\end{bmatrix}\\,.\n",
    "$$\n",
    "This matrix arises naturally in problems involving polynomial interpolation and\n",
    "differential equations. The determinant of $ V $ has a beautiful closed-form\n",
    "expression:\n",
    "$$\n",
    "    \\det(V) = \\prod_{0 \\leq i < j \\leq n} (x_j - x_i)\\,.\n",
    "$$\\,.\n",
    "This is the product of all possible differences between \n",
    "two values, with the first one having the larger index.\n",
    "\n",
    "(a) Write a procedure that creates a Vandermonde matrix for a given list of\n",
    "input values. _Hint:_ Start with a null matrix of the appropriate dimensions and\n",
    "fill the elements in one by one. Use a double for loop and the formula $ V_{ij}\n",
    "= x_i^j $.\n",
    "\n",
    "(b) Write a procedure which uses the closed formula above to compute the\n",
    "determinant of the Vandermonde matrix corresponding to a list of values.\n",
    "_Hint:_ Start with the value $ 1 $ for the determinant and use a double for loop\n",
    "to include one factor $ (x_j - x_i) $ at a time.\n",
    "\n",
    "(c) Test your functions on the matrix below. _Hint:_ Use `det` to check the\n",
    "determinant that your procedure from item (a) yields.\n",
    "$$\n",
    "V = V(2, 3, 5, 7, 11) = \\begin{bmatrix} \n",
    "1 & 2 & 4 & 8 & 16 \\\\ \n",
    "1 & 3 & 9 & 27 & 81 \\\\ \n",
    "1 & 5 & 25 & 125 & 625 \\\\ \n",
    "1 & 7 & 49 & 343 & 2401 \\\\ \n",
    "1 & 11 & 121 & 1331 & 14641\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
